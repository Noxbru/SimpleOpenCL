#summary User manual

= Manual summary = 
(under construction)

<wiki:toc max_depth="2" />

= Introduction =

This section shows how to use SimpleOpenCL. We only show First level functions in this section, that are the main goal of the project.

SimpleOpenCL eliminates the need of knowing about OpenCL objects. The only thing a programmer needs to know in order to use SimpleOpenCL is C, two SimpleOpenCL types, and few functions.

The functionality it offers is:

 # To select in which device you want to run your code.
 # To initialize the code you want to execute (OpenCL Kernels).
 # To execute the selected code in the selected device.

= Selecting the device =
SimpleOpenCL provides some functions in order to select the desired hardware. The user can choose any of those, depending on what he wants. All the functions use the "sclHard" SimpleOpenCL type, to represent a hardware device. Please refer to SimpleOpenCL Specification to know more about SimpleOpenCL types.

== sclGetAllHardware ==
This SimpleOpenCL function, returns a list with all the OpenCL compatible hardware on the system. 
{{{
sclHard* sclGetAllHardware( int* found );
}}}

It returns a list of hardware devices found as sclHard pointers, and gets an integer pointer as parameter to store the number of devices found.

*WARNING:* this function was different before version 0.010_27_02_2013. Download the latest SimpleOpenCL version to use it as explained on this section.

== sclGetFastestDevice ==

This function returns the fastest device considering the number of compute units, independently of the device type.

{{{
sclHard sclGetFastestDevice( sclHard* hardList, int found );
}}}  

== sclGetGPUHardware ==

This function allows the programmer to select GPU hardware. The nDevice parameter allows to specify exactly which device if there are more than one. 
{{{
sclHard                 sclGetGPUHardware( int nDevice, int* found );
}}}
== sclGetCPUHardware ==
This function allows the programmer to select CPU hardware. The nDevice parameter allows to specify exactly which device if there are more than one. 
{{{
sclHard                 sclGetCPUHardware( int nDevice, int* found );
}}}
= Selecting the code =
SimpleOpenCL also provides a function that allows to load a .cl file with one or more kernels, compile it at runtime, and if there was a compiling error on the .cl file, the compiling error messages will be printed on the command line (stdout).

{{{
sclSoft sclGetCLSoftware( char* path, char* name, sclHard hardware );
}}}

This function is sclGetCLSoftware, and takes the path of the source file to be loaded, the name of the kernel function to be called when executing the code, and the hardware that will execute it. It is necessary to specify the hardware, in order to let the OpenCL C compiler to know which binary (assembler) code it has to produce. The assembler code is completely hardware dependent. 

The function returns an sclSoft variable that reprents the compiled OpenCL kernel code. Please refer to SimpleOpenCL specification to know more about sclSoft and SimpleOpenCL types.

= Executing the code on the device =
Once we have selected the hardware and the software, we just have to execute it.

The function sclManageArgsLaunchKernel takes as arguments an "sclHard hardware" and an "sclSoft software", the NDRange kernel dimensions (global_work_size and local_work_size), a string that will contain the information about the parameters sent to the OpenCL Kernel (sizesValues), and a variable number of {{{void*}}} parameters (...). This {{{void*}}} parameters will be the parameter variables sent to the OpenCL kernel.

{{{
cl_event sclManageArgsLaunchKernel( sclHard hardware, 
                                   sclSoft software, 
                                   size_t *global_work_size, 
                                   size_t *local_work_size,
                                   const char* sizesValues, 
                                   ... );
}}}

In order to automatically do all the OpenCL hard work left at this stage of the code, this SimpleOpenCL function needs you to indicate three main things:
 # The size of each parameter variable.
 # What to do with this variable ( is it the input data for the kernel? or the output, or just a variable to be exclusively used by the hardware? )
 # In which memory layer should the variable be allocated? (Refer to OpenCL memory hierarchy to know more about memory layers in OpenCL C kernels).

To this end, SimpleOpenCL provides a short way to indicate this, with a printf-like codification. The programmer, should write a string as the "sizesValues" parameter. In this string, the information is written after a "%" like in the C printf standard function. A table of characters and its meaning is shown below.

|| *Character* || *Number of parameters* || *Action to be performed by SimpleOpenCL* || *Memory layer flags on the kernel code* ||
|| *%a* || 2 (size_t varSize,{{{void*}}} var)|| When SimpleOpenCL finds %a, it reads a size_t argument, and a {{{void*}}} argument in this order. It is intended for non pointer arguments like int, float etc. size_t size is the variable size in bytes and {{{void*}}} var is the pointer to the variable. This is a read only parameter. || __global, __constant ||
|| *%N* || 1 (size_t varSize)|| When SimpleOpenCL finds %N, it sets a local memory pointer with size "varSize" || __local ||
|| *%w* || 2 (size_t varSize, {{{void*}}} var) || Wirte only. When SimpleOpenCL finds %w, it sets a global memory pointer with size "varSize". When the execution of the kernel is done, it automatically copies the results from the hardware to the variable "var". || __global ||
|| *%r* || 2 (size_t varSize, {{{void*}}} var) || Read only. When SimpleOpenCL finds %r it sets a global memory pointer with size "varSize". Before the execution of the kernel, the contents of "var" are copied to the hardware device selected. || __global, __constant ||
|| *%R* || 2 (size_t varSize, {{{void*}}} var) || Read write. When SimpleOpenCL finds %R it sets a global memory pointer with size "varSize". Before the execution of the kernel, the contents of "var" are copied to the hardware device selected. When the execution of the kernel is done, it automatically copies the results from the hardware to the variable "var". || __global ||
|| *%g* || 1 (size_t varSize) || When SimpleOpenCL finds %g it sets a global memory pointer with size "varSize" in read write mode. Tis pointer will not be read or written from the main program. || __global ||

= Compiling the code =

SimpleOpenCL code consists by now of only one C file (simpleCL.c), and it's header file (simpleCL.h). To compile your program, you have to compile your code along with simpleCL.c. It is very fast to compile since it is a quite short, but useful code.

Each OpenCL implementation comes with a manual for compiling it, indicating necessary libraries and compiler flags. The question is, if you know how to compile OpenCL, you know how to compile SimpleOpenCL, since it is an OpenCL code.

Compiling in Linux with AMD OpenCL 1.2 implementation:

{{{
gcc -O3 -I/opt/AMDAPP/include main.c simpleCL.c -o myapp -lOpenCL
}}}

Compiling in OS X:

{{{
gcc -O3 main.c simpleCL.c -o myapp -framework OpenCL
}}}


= Short example = 

In this example, we show a SimpleOpenCL program that generates a vector of 134217728 float values that start at 0 and end at 134217728-1, and a float variable with the value "3" on the Host. Later it sends this values to the first device found on the system and executes a kernel where each WorkItem multiplies the value of the vector corresponding to its global index in the x dimension, by the value "3", and stores the result on the same vector position.

This is the SimpleOpenCL Host code:

{{{
#include "simpleCL.h"

int main( int argc, char *argv[] ){

        float* vector;
        float value;
        int i,found;
        /* SimpleOpenCL types declaration */
        sclHard* hardware;
        sclSoft software;

        /* NDRange 2D size initialization*/
        size_t global_size[2];
        size_t local_size[2];
        size_t dataLength=134217728;
        size_t dataSize=sizeof(float)*dataLength;
    
        global_size[0]=dataLength; global_size[1]=1;
        local_size[0]=64; local_size[1]=1;

        /* Data generation */
        vector = (float*)malloc(dataSize);
        value = 3;
        for (i=0; i<dataLength; i++){
                vector[i] = (float)i;
        }   

        /* Hardware and Software initialization */
        found=0;
        hardware = sclGetAllHardware(&found);
        software = sclGetCLSoftware("example2.cl","example2",hardware[0]);

        /* Kernel execution */
        sclManageArgsLaunchKernel( hardware[0], software,
                                   global_size, local_size,
                                   "%R %r %N",
                                   dataSize, (void*)vector, sizeof(float), (void*)&value, sizeof(float));

        /* Data is read back from the device automatically */
        /* We print some values to check the results */
        printf("\nExecution successful\n");
        printf("vector[0]=%f vector[10]=%f vector[200]=%f\n",vector[0],vector[10],vector[200]);

        return 0;
    
}
}}}

As we can see on the code above, we have used a read/write variable (%R), a read only variable (%r) and a local memory variable (%N).

Now the kernel code:

{{{
/* Kernel and kernel parameters declaration*/
__kernel void example2( __global float *vector,
                        __global float *value,
                        __local float *valueLocal){
        /* Reading the WorkItem index*/
        int local_x = get_local_id(0);
        int global_x = get_global_id(0);
            
        /* Copying the read only value to local memory for faster broadcast reads */
        if (local_x == 0) {
                *valueLocal=*value;
        }   
        /* Final multiplication, stored on the same vector */
        vector[global_x] = vector[global_x] * *valueLocal;
        /* Barrier to avoid that some OpenCL implementation */
        /* optimizations start reading results from the device to the Host */
        /* before they are copied to global memory. */ 
        barrier(CLK_GLOBAL_MEM_FENCE);
}
}}}

Thi code is executed super fast both on the GPU and the CPU. Note that NDRange kernels, even designed for GPU's, when executed on the CPU are not simulated but compiled and optimized for the target CPU. So performance must be very decent.

Compiling this code with gcc on a Mac, looks like this:

{{{
gcc -O3 main.c simpleCL.c -o myapp -framework OpenCL
}}}

And finally, this is the output on an Apple Macbook Air, with a Core i7 3667U CPU. This CPU has an OpenCL compatible GPU, but the GPU driver for OpenCL is not yet available, so the code is executed on the CPU part.

{{{
Group 1 with 1 devices
 Device 0 
 Platform name: Apple 
 Vendor: Apple 
 Device name: Intel(R) Core(TM) i7-3667U CPU @ 2.00GHz
Execution successful
vector[0]=0.000000 vector[10]=30.000000 vector[200]=600.000000
}}}